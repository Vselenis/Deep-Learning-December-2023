{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a072fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cabc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    try:\n",
    "        df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "        df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' does not exist or the name is different.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the file: {e}\")\n",
    "        return None, None\n",
    "    return df_benchmark, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6162104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4645f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights, target_size):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    # Penalize if the sample size is not the target size\n",
    "    row_count_diff = abs(len(selected_indices) - target_size) * 1000  # Large penalty for incorrect size\n",
    "    return percentage_diff + row_count_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0683ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size=150, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define bounds for exactly target_size rows\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights, target_size), maxiter=maxiter)\n",
    "    \n",
    "    # Ensure exactly target_size unique rows\n",
    "    selected_indices = list(set(int(i) for i in result.x))\n",
    "    if len(selected_indices) > target_size:\n",
    "        selected_indices = np.random.choice(selected_indices, target_size, replace=False)\n",
    "    elif len(selected_indices) < target_size:\n",
    "        extra_indices = np.random.choice([i for i in range(len(df_benchmark)) if i not in selected_indices],\n",
    "                                         target_size - len(selected_indices), replace=False)\n",
    "        selected_indices = np.concatenate([selected_indices, extra_indices])\n",
    "\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9203fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    with pd.ExcelWriter(filename, mode='a', if_sheet_exists='overlay') as writer:\n",
    "        sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "        new_sample_col = f'Sample {len(sample_columns) + 1}'  # Define new sample column\n",
    "\n",
    "        benchmark_df[new_sample_col] = 0  # Initialize to 0 for all rows\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set selected rows to 1\n",
    "\n",
    "        # Write updated benchmark and target data back to the Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d91e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "    if df_benchmark is None or df_target is None:\n",
    "        return  # Exit if file loading failed\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Set the exact target size\n",
    "    target_size = 135\n",
    "\n",
    "    # Run simulated annealing to find the best sample\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the selected sample to Excel\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2290b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
