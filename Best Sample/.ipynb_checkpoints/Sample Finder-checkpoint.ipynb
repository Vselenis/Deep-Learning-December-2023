{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624b2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5252b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7592eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f24c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    return percentage_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71ede2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(len(df_target))]  # Define the range for row selection\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights), maxiter=maxiter)\n",
    "    \n",
    "    selected_indices = [int(i) for i in result.x]  # Get the best rows selected\n",
    "    return selected_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d9b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write results to Excel, updated to take both df_benchmark and df_target\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    with pd.ExcelWriter(filename, mode='a', if_sheet_exists='replace') as writer:\n",
    "        new_sample_col = f'Sample {len(benchmark_df.columns) - 1}'  # For a new sample column\n",
    "\n",
    "        # Add a new column for selected rows\n",
    "        benchmark_df[new_sample_col] = 0\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set to 1 for selected rows\n",
    "\n",
    "        # Write both DataFrames to separate sheets in the same Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c0d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaming PC\\AppData\\Local\\Temp\\ipykernel_3012\\238021454.py:14: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Perform simulated annealing to find the best rows\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights)\n",
    "\n",
    "    # Write the results back to the Excel file, adding a new sample column\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0512b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107d862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c7cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0face6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    return percentage_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73aa3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define the range for row selection\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights), maxiter=maxiter)\n",
    "    \n",
    "    selected_indices = [int(i) for i in result.x]  # Get the best rows selected\n",
    "    return selected_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179a6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    # Open the Excel writer in append mode with openpyxl\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        # Load existing sample columns\n",
    "        sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "        new_sample_col = f'Sample {len(sample_columns) + 1}'  # Define new sample column\n",
    "\n",
    "        benchmark_df[new_sample_col] = 0  # Initialize to 0 for all rows\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set selected rows to 1\n",
    "\n",
    "        # Write updated benchmark and target data back to the Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        df_target.to_excel(writer, sheet_name='Target', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d377e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Write the selected sample to Excel\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mwrite_results_to_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_benchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mwrite_results_to_excel\u001b[1;34m(benchmark_df, selected_indices, filename)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Write updated benchmark and target data back to the Excel file\u001b[39;00m\n\u001b[0;32m     13\u001b[0m benchmark_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mdf_target\u001b[49m\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_target' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Define the desired target\n",
    "    target_size = 30\n",
    "\n",
    "    # Run simulated annealing to find the best sample\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the selected sample to Excel\n",
    "    write_results_to_excel(df_benchmark, selected_indices)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e513c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target\n",
    "\n",
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }\n",
    "\n",
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    return percentage_diff\n",
    "\n",
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define the range for row selection\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights), maxiter=maxiter)\n",
    "    \n",
    "    selected_indices = [int(i) for i in result.x]  # Get the best rows selected\n",
    "    return selected_indices\n",
    "\n",
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    # Open the Excel writer in append mode with openpyxl\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        # Load existing sample columns\n",
    "        sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "        new_sample_col = f'Sample {len(sample_columns) + 1}'  # Define new sample column\n",
    "\n",
    "        benchmark_df[new_sample_col] = 0  # Initialize to 0 for all rows\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set selected rows to 1\n",
    "\n",
    "        # Write updated benchmark and target data back to the Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Define the desired target\n",
    "    target_size = 30\n",
    "\n",
    "    # Run simulated annealing to find the best sample\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the selected sample to Excel\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e20f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0daf97b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 101>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Write the results back to the Excel file, adding a new sample column\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[43mwrite_results_to_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_benchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mwrite_results_to_excel\u001b[1;34m(benchmark_df, selected_indices, filename)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save both sheets back to the Excel file\u001b[39;00m\n\u001b[0;32m     72\u001b[0m benchmark_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBenchmark\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mdf_target\u001b[49m\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m writer\u001b[38;5;241m.\u001b[39msave()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_target' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target\n",
    "\n",
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }\n",
    "\n",
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    return percentage_diff\n",
    "\n",
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define the range for row selection\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights), maxiter=maxiter)\n",
    "    \n",
    "    selected_indices = [int(i) for i in result.x]  # Get the best rows selected\n",
    "    return selected_indices\n",
    "\n",
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    try:\n",
    "        book = load_workbook(filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "        return\n",
    "    \n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "    \n",
    "    sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "    new_sample_col = f'Sample {len(sample_columns) + 1}'  # Create a new column for the current sample\n",
    "\n",
    "    benchmark_df[new_sample_col] = 0  # Default to 0 for all rows\n",
    "    benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set to 1 for selected rows\n",
    "    \n",
    "    # Save both sheets back to the Excel file\n",
    "    benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "    df_target.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Define the desired target size (e.g., 300 rows instead of 250)\n",
    "    target_size = 300\n",
    "\n",
    "    # Perform simulated annealing to find the best rows\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the results back to the Excel file, adding a new sample column\n",
    "    write_results_to_excel(df_benchmark, selected_indices)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f77f8f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 102>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m target_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Run simulated annealing to find the best sample\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m \u001b[43msimulated_annealing_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_benchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Write the selected sample to Excel\u001b[39;00m\n\u001b[0;32m     99\u001b[0m write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36msimulated_annealing_sampling\u001b[1;34m(df_benchmark, df_target, weights, target_size, maxiter)\u001b[0m\n\u001b[0;32m     48\u001b[0m target_metrics \u001b[38;5;241m=\u001b[39m calculate_metrics(df_target, \u001b[38;5;28mlen\u001b[39m(df_target), weights)  \u001b[38;5;66;03m# Get target metrics\u001b[39;00m\n\u001b[0;32m     50\u001b[0m bounds \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_benchmark) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(target_size)]  \u001b[38;5;66;03m# Define bounds for exactly target_size rows\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdual_annealing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_benchmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Ensure exactly target_size unique rows\u001b[39;00m\n\u001b[0;32m     55\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mx))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_dual_annealing.py:653\u001b[0m, in \u001b[0;36mdual_annealing\u001b[1;34m(func, bounds, args, maxiter, minimizer_kwargs, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;66;03m# Initialization of the energy state\u001b[39;00m\n\u001b[0;32m    652\u001b[0m energy_state \u001b[38;5;241m=\u001b[39m EnergyState(lower, upper, callback)\n\u001b[1;32m--> 653\u001b[0m \u001b[43menergy_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;66;03m# Minimum value of annealing temperature reached to perform\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# re-annealing\u001b[39;00m\n\u001b[0;32m    656\u001b[0m temperature_restart \u001b[38;5;241m=\u001b[39m initial_temp \u001b[38;5;241m*\u001b[39m restart_temp_ratio\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_dual_annealing.py:172\u001b[0m, in \u001b[0;36mEnergyState.reset\u001b[1;34m(self, func_wrapper, rand_gen, x0)\u001b[0m\n\u001b[0;32m    170\u001b[0m reinit_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m init_error:\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_energy \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_energy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObjective function is returning None\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_dual_annealing.py:381\u001b[0m, in \u001b[0;36mObjectiveFunWrapper.fun\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(x, df_benchmark, df_target, target_metrics, weights)\u001b[0m\n\u001b[0;32m     40\u001b[0m     percentage_diff \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[key] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m((sample_metrics[key] \u001b[38;5;241m-\u001b[39m target_metrics[key]) \u001b[38;5;241m/\u001b[39m target_metrics[key]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Penalize if the sample size is not the target size\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m row_count_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mlen\u001b[39m(selected_indices) \u001b[38;5;241m-\u001b[39m \u001b[43mtarget_size\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# Large penalty for incorrect size\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m percentage_diff \u001b[38;5;241m+\u001b[39m row_count_diff\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_size' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target\n",
    "\n",
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }\n",
    "\n",
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    # Penalize if the sample size is not the target size\n",
    "    row_count_diff = abs(len(selected_indices) - target_size) * 1000  # Large penalty for incorrect size\n",
    "    return percentage_diff + row_count_diff\n",
    "\n",
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size=150, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define bounds for exactly target_size rows\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights), maxiter=maxiter)\n",
    "    \n",
    "    # Ensure exactly target_size unique rows\n",
    "    selected_indices = list(set(int(i) for i in result.x))\n",
    "    if len(selected_indices) > target_size:\n",
    "        selected_indices = np.random.choice(selected_indices, target_size, replace=False)\n",
    "    elif len(selected_indices) < target_size:\n",
    "        extra_indices = np.random.choice([i for i in range(len(df_benchmark)) if i not in selected_indices],\n",
    "                                         target_size - len(selected_indices), replace=False)\n",
    "        selected_indices = np.concatenate([selected_indices, extra_indices])\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    with pd.ExcelWriter(filename, mode='a', if_sheet_exists='overlay') as writer:\n",
    "        sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "        new_sample_col = f'Sample {len(sample_columns) + 1}'  # Define new sample column\n",
    "\n",
    "        benchmark_df[new_sample_col] = 0  # Initialize to 0 for all rows\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set selected rows to 1\n",
    "\n",
    "        # Write updated benchmark and target data back to the Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Set the exact target size\n",
    "    target_size = 150\n",
    "\n",
    "    # Run simulated annealing to find the best sample\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the selected sample to Excel\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c10fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import dual_annealing\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target\n",
    "\n",
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    clients_with_payments = df['LP'].notnull().sum() / len(df)  # % of clients with payments\n",
    "    total_paid = df['Payments'].sum()  # Total paid\n",
    "    total_debt = df['Deb'].sum()  # Total debt\n",
    "    collection_percentage = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0  # % of collection\n",
    "\n",
    "    averages = df.mean(skipna=True)  # Calculate averages for all columns, skipping empty cells\n",
    "\n",
    "    return {\n",
    "        'Deb': averages['Deb'],\n",
    "        'GR': averages['GR'],\n",
    "        'DPD': averages['DPD'],\n",
    "        'LP': averages['LP'],  # Average of LP column\n",
    "        'collection': collection_percentage,  # % of collection\n",
    "        'payments': clients_with_payments  # % of clients with payments\n",
    "    }\n",
    "\n",
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(x, df_benchmark, df_target, target_metrics, weights, target_size):\n",
    "    selected_indices = [int(i) for i in x]  # Convert row numbers to integers\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    # Penalize if the sample size is not the target size\n",
    "    row_count_diff = abs(len(selected_indices) - target_size) * 1000  # Large penalty for incorrect size\n",
    "    return percentage_diff + row_count_diff\n",
    "\n",
    "# Simulated annealing function to find the best rows\n",
    "def simulated_annealing_sampling(df_benchmark, df_target, weights, target_size=150, maxiter=500):\n",
    "    target_metrics = calculate_metrics(df_target, len(df_target), weights)  # Get target metrics\n",
    "    \n",
    "    bounds = [(0, len(df_benchmark) - 1) for _ in range(target_size)]  # Define bounds for exactly target_size rows\n",
    "    \n",
    "    result = dual_annealing(objective_function, bounds, args=(df_benchmark, df_target, target_metrics, weights, target_size), maxiter=maxiter)\n",
    "    \n",
    "    # Ensure exactly target_size unique rows\n",
    "    selected_indices = list(set(int(i) for i in result.x))\n",
    "    if len(selected_indices) > target_size:\n",
    "        selected_indices = np.random.choice(selected_indices, target_size, replace=False)\n",
    "    elif len(selected_indices) < target_size:\n",
    "        extra_indices = np.random.choice([i for i in range(len(df_benchmark)) if i not in selected_indices],\n",
    "                                         target_size - len(selected_indices), replace=False)\n",
    "        selected_indices = np.concatenate([selected_indices, extra_indices])\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "# Function to write the results to the existing Excel file, adding a new sample column each time\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    with pd.ExcelWriter(filename, mode='a', if_sheet_exists='overlay') as writer:\n",
    "        sample_columns = [col for col in benchmark_df.columns if col.startswith('Sample')]\n",
    "        new_sample_col = f'Sample {len(sample_columns) + 1}'  # Define new sample column\n",
    "\n",
    "        benchmark_df[new_sample_col] = 0  # Initialize to 0 for all rows\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set selected rows to 1\n",
    "\n",
    "        # Write updated benchmark and target data back to the Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Deb': 0.1,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Set the exact target size\n",
    "    target_size = 100\n",
    "\n",
    "    # Run simulated annealing to find the best sample\n",
    "    selected_indices = simulated_annealing_sampling(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the selected sample to Excel\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe6c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
