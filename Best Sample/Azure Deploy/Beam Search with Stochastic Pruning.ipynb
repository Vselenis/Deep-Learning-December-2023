{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f7f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to import the data from the Excel file\n",
    "def load_datasets(filename='benchmark_target.xlsx'):\n",
    "    df_benchmark = pd.read_excel(filename, sheet_name='Benchmark')\n",
    "    df_target = pd.read_excel(filename, sheet_name='Target')\n",
    "    return df_benchmark, df_target\n",
    "\n",
    "# Function to calculate the necessary metrics for both datasets\n",
    "def calculate_metrics(df, target_size, weights):\n",
    "    # Initialize metrics with default values\n",
    "    metrics = {\n",
    "        'Debt': None,\n",
    "        'DPD': None,\n",
    "        'GR': None,\n",
    "        'LP': None,\n",
    "        'GRDPD': None,\n",
    "        'GRLP': None,\n",
    "        'collection': None,\n",
    "        'payments': None,\n",
    "    }\n",
    "\n",
    "    # Calculate averages for the available columns\n",
    "    for col in ['Debt', 'DPD', 'GR', 'LP', 'GRDPD', 'GRLP']:\n",
    "        if col in df.columns:\n",
    "            metrics[col] = df[col].mean()\n",
    "\n",
    "    # Check for collection and payments\n",
    "    if 'Payments' in df.columns:\n",
    "        # If Payments column exists\n",
    "        total_paid = df['Payments'].sum()\n",
    "        total_debt = df['Debt'].sum() if 'Debt' in df.columns else 0\n",
    "        metrics['collection'] = total_paid / (total_debt + total_paid) if total_debt + total_paid != 0 else 0\n",
    "        metrics['payments'] = df['Payments'].notnull().sum() / len(df)\n",
    "    elif 'LP' in df.columns:\n",
    "        # If LP column exists\n",
    "        metrics['payments'] = df['LP'].notnull().sum() / len(df)\n",
    "    else:\n",
    "        # If neither Payments nor LP columns exist\n",
    "        metrics['collection'] = None\n",
    "        metrics['payments'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Objective function to minimize the difference between benchmark and target metrics\n",
    "def objective_function(selected_indices, df_benchmark, df_target, target_metrics, weights):\n",
    "    sample = df_benchmark.iloc[selected_indices]  # Select rows based on indices\n",
    "    sample_metrics = calculate_metrics(sample, len(selected_indices), weights)  # Calculate metrics for sample\n",
    "\n",
    "    # Calculate the weighted percentage difference\n",
    "    percentage_diff = 0\n",
    "    for key in weights.keys():\n",
    "        percentage_diff += weights[key] * abs((sample_metrics[key] - target_metrics[key]) / target_metrics[key]) * 100\n",
    "\n",
    "    return percentage_diff\n",
    "\n",
    "# Beam Search with Stochastic Pruning\n",
    "def beam_search_stochastic_pruning(df_benchmark, df_target, weights, target_size, beam_width=50):\n",
    "    target_metrics = calculate_metrics(df_target, target_size, weights)\n",
    "    candidates = [[]]  # Start with an empty candidate list\n",
    "\n",
    "    for _ in range(target_size):\n",
    "        new_candidates = []\n",
    "        \n",
    "        # Expand each candidate in the current beam\n",
    "        for candidate in candidates:\n",
    "            available_indices = [i for i in range(len(df_benchmark)) if i not in candidate]\n",
    "            \n",
    "            # Assign a higher probability to rows not yet included in the candidate solution\n",
    "            probabilities = [1.0 / (i + 1) for i in range(len(available_indices))]\n",
    "            probabilities = np.array(probabilities) / sum(probabilities)  # Normalize probabilities\n",
    "            \n",
    "            # Sample indices stochastically based on probabilities\n",
    "            sampled_indices = np.random.choice(available_indices, size=min(beam_width, len(available_indices)), replace=False, p=probabilities)\n",
    "\n",
    "            for idx in sampled_indices:\n",
    "                new_candidate = candidate + [idx]  # Add new row index to candidate\n",
    "                # Deduplicate by ensuring unique row indices in each candidate\n",
    "                if len(new_candidate) == len(set(new_candidate)):\n",
    "                    new_candidates.append(new_candidate)\n",
    "\n",
    "        # Sort new candidates by their objective function value and keep the top beam_width candidates\n",
    "        new_candidates = sorted(new_candidates, key=lambda x: objective_function(x, df_benchmark, df_target, target_metrics, weights))\n",
    "        candidates = new_candidates[:beam_width]\n",
    "\n",
    "    # Return the best candidate from the final set\n",
    "    best_solution = min(candidates, key=lambda x: objective_function(x, df_benchmark, df_target, target_metrics, weights))\n",
    "    return best_solution\n",
    "\n",
    "# Function to write results to Excel, updated to take both df_benchmark and df_target\n",
    "def write_results_to_excel(benchmark_df, target_df, selected_indices, filename='benchmark_target.xlsx'):\n",
    "    with pd.ExcelWriter(filename, mode='a', if_sheet_exists='replace') as writer:\n",
    "        new_sample_col = f'Sample {len(benchmark_df.columns) - 1}'  # For a new sample column\n",
    "\n",
    "        # Add a new column for selected rows\n",
    "        benchmark_df[new_sample_col] = 0\n",
    "        benchmark_df.loc[selected_indices, new_sample_col] = 1  # Set to 1 for selected rows\n",
    "\n",
    "        # Write both DataFrames to separate sheets in the same Excel file\n",
    "        benchmark_df.to_excel(writer, sheet_name='Benchmark', index=False)\n",
    "        target_df.to_excel(writer, sheet_name='Target', index=False)\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    df_benchmark, df_target = load_datasets('benchmark_target.xlsx')  # Load datasets from Excel\n",
    "\n",
    "    # Define the column weights\n",
    "    weights = {\n",
    "        'Debt': 0.2,\n",
    "        'GR': 0.2,\n",
    "        'DPD': 0.2,\n",
    "        'LP': 0.2,\n",
    "        'collection': 0.1,\n",
    "        'payments': 0.1\n",
    "    }\n",
    "\n",
    "    # Perform Beam Search with Stochastic Pruning to select the best rows\n",
    "    target_size = 95  # Adjust the target size as needed\n",
    "    selected_indices = beam_search_stochastic_pruning(df_benchmark, df_target, weights, target_size)\n",
    "\n",
    "    # Write the results back to the Excel file, adding a new sample column\n",
    "    write_results_to_excel(df_benchmark, df_target, selected_indices)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}