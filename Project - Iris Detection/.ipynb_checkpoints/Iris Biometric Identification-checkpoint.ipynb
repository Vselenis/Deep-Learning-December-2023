{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea170d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e18b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = \"./data/iris_thousands.csv\"\n",
    "BASE_DIR = \"./data/CASIA-Iris-Thousand/\"\n",
    "NUM_CLASSES = 2000\n",
    "IMAGE_WIDTH = 640    \n",
    "IMAGE_HEIGHT = 480\n",
    "IMAGE_CHANNELS = 1\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_SIZE_CHANNELS = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c915c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All image paths are valid and exist in the dataset directory.\n",
      "Updated dataset saved to: ./data/iris_thousands.csv\n"
     ]
    }
   ],
   "source": [
    "def update_paths(csv_file, base_dir):\n",
    "    iris_df = pd.read_csv(csv_file)\n",
    "    \n",
    "    corrected_paths = []\n",
    "    missing_files = []\n",
    "\n",
    "    for index, row in iris_df.iterrows():\n",
    "        label = row['Label']  # Assuming 'Label' column contains the format \"<subject_id>-<L/R>\"\n",
    "        image_filename = os.path.basename(row['ImagePath'])  # Extract the image file name\n",
    "        subject_id, eye = label.split(\"-\")  # Split into subject ID and eye (L/R)\n",
    "        corrected_path = os.path.join(base_dir, subject_id, eye, image_filename)\n",
    "        corrected_paths.append(corrected_path)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(corrected_path):\n",
    "            missing_files.append(corrected_path)\n",
    "\n",
    "    # Add a new column \"Images\" to the dataset with the corrected paths\n",
    "    iris_df[\"ImagesPath\"] = corrected_paths\n",
    "\n",
    "    # Check and print status of the file paths\n",
    "    if not missing_files:\n",
    "        print(\"All image paths are valid and exist in the dataset directory.\")\n",
    "    else:\n",
    "        print(f\"{len(missing_files)} missing image(s) found:\")\n",
    "        for file in missing_files:\n",
    "            print(file)\n",
    "\n",
    "    iris_df.to_csv(csv_file, index=False)\n",
    "    print(f\"Updated dataset saved to: {csv_file}\")\n",
    "    return iris_df\n",
    "\n",
    "iris_data = update_paths(CSV_FILE, BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa965ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437-R    10\n",
      "700-L    10\n",
      "149-R    10\n",
      "241-L    10\n",
      "241-R    10\n",
      "         ..\n",
      "452-L    10\n",
      "452-R    10\n",
      "151-L    10\n",
      "151-R    10\n",
      "715-L    10\n",
      "Name: Label, Length: 2000, dtype: int64\n",
      "Class distribution is balanced.\n"
     ]
    }
   ],
   "source": [
    "def check_class_distribution(dataset):\n",
    "    class_counts = dataset['Label'].value_counts()\n",
    "    print(class_counts)\n",
    "\n",
    "    # Check for imbalances\n",
    "    if class_counts.min() != class_counts.max():\n",
    "        print(\"Class distribution is imbalanced.\")\n",
    "    else:\n",
    "        print(\"Class distribution is balanced.\")\n",
    "\n",
    "check_class_distribution(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1044a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_dimensions(dataset, image_size):\n",
    "    incorrect_dimensions = []\n",
    "    for image_path in dataset[\"ImagesPath\"]:\n",
    "        img = Image.open(image_path)\n",
    "        if img.size != image_size[:2]:  # Check width and height\n",
    "            incorrect_dimensions.append((image_path, img.size))\n",
    "\n",
    "    if incorrect_dimensions:\n",
    "        print(f\"{len(incorrect_dimensions)} image(s) with incorrect dimensions:\")\n",
    "        for file, size in incorrect_dimensions:\n",
    "            print(f\"{file} has size {size}\")\n",
    "    else:\n",
    "        print(\"All images have correct dimensions.\")\n",
    "\n",
    "check_image_dimensions(iris_data, IMAGE_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
