{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e8d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fcac663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f66339",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv(\"./data/adult.data\", sep=\",\", engine=\"python\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "426fac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee2cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      income_class  \n",
       "0            <=50K  \n",
       "1            <=50K  \n",
       "2            <=50K  \n",
       "3            <=50K  \n",
       "4            <=50K  \n",
       "...            ...  \n",
       "32556        <=50K  \n",
       "32557         >50K  \n",
       "32558        <=50K  \n",
       "32559        <=50K  \n",
       "32560         >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc065dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes, income_target = income_data.drop(columns = [\"income_class\"]), income_data.income_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f45b1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = income_attributes.drop(columns = [\"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e346380",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_target = income_target.str.strip()  \n",
    "income_target = income_target.replace({\"<=50K\": 0, \">50K\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eded9fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "32556    0\n",
       "32557    1\n",
       "32558    0\n",
       "32559    0\n",
       "32560    1\n",
       "Name: income_class, Length: 32561, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dff0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = pd.get_dummies(income_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6983bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes_train, income_attributes_test, income_target_train, income_target_test = train_test_split(\n",
    "    income_attributes, income_target, stratify=income_target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29fefd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 107), (6513, 107), (26048,), (6513,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_attributes_train.shape, income_attributes_test.shape, income_target_train.shape, income_target_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fcedab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "income_attributes_train_scaled = scaler.fit_transform(income_attributes_train)\n",
    "income_attributes_test_scaled = scaler.fit_transform(income_attributes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b3b83f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes = income_attributes.shape[1]\n",
    "num_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b58ef38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = Sequential([\n",
    "    Input(shape=(num_attributes,)),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "], name = \"log_regr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbb69cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_regr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108 (432.00 Byte)\n",
      "Trainable params: 108 (432.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logistic_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daa255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS CLASSIFICATION 5classes\n",
    "# logistic_regression = Sequential([\n",
    "#     Input(shape=(num_attributes,)),\n",
    "#     Dense(5, activation = \"softmax\")\n",
    "# ], name = \"log_regr\")\n",
    "# logistic_regression.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5045e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14270    0\n",
       "13402    0\n",
       "28612    0\n",
       "26908    0\n",
       "12522    1\n",
       "        ..\n",
       "9144     0\n",
       "5445     0\n",
       "16738    0\n",
       "5951     0\n",
       "13981    0\n",
       "Name: income_class, Length: 26048, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be5c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b4d1410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 13.9654\n",
      "Epoch 2/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1059.2460\n",
      "Epoch 3/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1006.6783\n",
      "Epoch 4/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 893.6676\n",
      "Epoch 5/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 744.3319\n",
      "Epoch 6/99\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 624.6620\n",
      "Epoch 7/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 481.0245\n",
      "Epoch 8/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 356.5741\n",
      "Epoch 9/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 219.0136\n",
      "Epoch 10/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 90.3773\n",
      "Epoch 11/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 467.9680\n",
      "Epoch 12/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1082.2809\n",
      "Epoch 13/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 955.1678\n",
      "Epoch 14/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 815.6530\n",
      "Epoch 15/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 691.6908\n",
      "Epoch 16/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 546.7277\n",
      "Epoch 17/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 429.7498\n",
      "Epoch 18/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 281.9184\n",
      "Epoch 19/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 149.3212\n",
      "Epoch 20/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 34.2570\n",
      "Epoch 21/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1002.9354\n",
      "Epoch 22/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1026.2334\n",
      "Epoch 23/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 882.1967\n",
      "Epoch 24/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 758.9693\n",
      "Epoch 25/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 619.8616\n",
      "Epoch 26/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 492.9966\n",
      "Epoch 27/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 357.5899\n",
      "Epoch 28/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 224.6378\n",
      "Epoch 29/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 95.7100\n",
      "Epoch 30/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 423.0192\n",
      "Epoch 31/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1094.2651\n",
      "Epoch 32/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 951.9862\n",
      "Epoch 33/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 831.1379\n",
      "Epoch 34/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 682.9803\n",
      "Epoch 35/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 567.7119\n",
      "Epoch 36/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 418.9520\n",
      "Epoch 37/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 302.3112\n",
      "Epoch 38/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 156.6335\n",
      "Epoch 39/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 34.1332\n",
      "Epoch 40/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 967.1417\n",
      "Epoch 41/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1026.9626\n",
      "Epoch 42/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 892.9521\n",
      "Epoch 43/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 760.3992\n",
      "Epoch 44/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 629.4755\n",
      "Epoch 45/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 491.4760\n",
      "Epoch 46/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 367.5585\n",
      "Epoch 47/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 226.6249\n",
      "Epoch 48/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 105.5711\n",
      "Epoch 49/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 378.0283\n",
      "Epoch 50/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1102.8405\n",
      "Epoch 51/99\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 954.5208\n",
      "Epoch 52/99\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 837.4354\n",
      "Epoch 53/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 691.0707\n",
      "Epoch 54/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 568.4510\n",
      "Epoch 55/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 428.7002\n",
      "Epoch 56/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 303.0080\n",
      "Epoch 57/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 166.6986\n",
      "Epoch 58/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 34.0260\n",
      "Epoch 59/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 930.7579\n",
      "Epoch 60/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1027.0165\n",
      "Epoch 61/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 900.8910\n",
      "Epoch 62/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 758.1713\n",
      "Epoch 63/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 638.6539\n",
      "Epoch 64/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 492.5899\n",
      "Epoch 65/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 376.5201\n",
      "Epoch 66/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 227.2903\n",
      "Epoch 67/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 110.4155\n",
      "Epoch 68/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 339.4616\n",
      "Epoch 69/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1102.1965\n",
      "Epoch 70/99\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 962.5867\n",
      "Epoch 71/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 837.3443\n",
      "Epoch 72/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 700.6005\n",
      "Epoch 73/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 568.3450\n",
      "Epoch 74/99\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 437.5705\n",
      "Epoch 75/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 301.2637\n",
      "Epoch 76/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 175.3067\n",
      "Epoch 77/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 33.5313\n",
      "Epoch 78/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 894.6116\n",
      "Epoch 79/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1026.8881\n",
      "Epoch 80/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 910.3904\n",
      "Epoch 81/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 761.0500\n",
      "Epoch 82/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 644.5295\n",
      "Epoch 83/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 499.2662\n",
      "Epoch 84/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 377.3057\n",
      "Epoch 85/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 237.2969\n",
      "Epoch 86/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 112.3749\n",
      "Epoch 87/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 304.8289\n",
      "Epoch 88/99\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1101.7891\n",
      "Epoch 89/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 971.8449\n",
      "Epoch 90/99\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 836.8828\n",
      "Epoch 91/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 709.8641\n",
      "Epoch 92/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 567.8859\n",
      "Epoch 93/99\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 446.9777\n",
      "Epoch 94/99\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 301.2744\n",
      "Epoch 95/99\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 184.6877\n",
      "Epoch 96/99\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 35.9190\n",
      "Epoch 97/99\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 856.6001\n",
      "Epoch 98/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1032.8868\n",
      "Epoch 99/99\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 913.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21f222e7430>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(income_attributes_train, income_target_train, epochs=99,batch_size= len(income_attributes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f2c0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    Input(shape=(num_attributes,)),\n",
    "    \n",
    "    Dense(30, activation = \"relu\"),\n",
    "    Dense(20, activation = \"relu\"),\n",
    "    Dense(10, activation = \"relu\"),\n",
    "    \n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "], name = \"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f825c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\",tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0818f416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "814/814 [==============================] - 2s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 2/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 3/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 4/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 5/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 6/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 7/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 8/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 9/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 10/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 11/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 12/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 13/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 14/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 15/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 16/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 17/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 18/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 19/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 20/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 21/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 22/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 23/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 24/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 25/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 26/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 27/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 28/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 29/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 30/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 31/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 32/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 33/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 34/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 35/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 36/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 37/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 38/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 39/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 40/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 41/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 42/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 43/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 44/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 45/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 46/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 47/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 48/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 49/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 50/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 51/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 52/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 53/99\n",
      "814/814 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 54/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 55/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 56/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 57/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 58/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 59/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 60/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 61/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 62/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 63/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 64/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 65/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 66/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 67/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 68/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 69/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 70/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 71/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 72/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 73/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 74/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 75/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 76/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 77/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 78/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 79/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 80/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 81/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 82/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 83/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 84/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 85/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 86/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 87/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 88/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 89/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 90/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 91/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 92/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 93/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 94/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 95/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 96/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 97/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 98/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n",
      "Epoch 99/99\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7592 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21f29bf2650>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(income_attributes_train, income_target_train, epochs=99)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
